---
title: "PSY 503: Foundations of Statistical Methods in Psychological Science"
subtitle: "Introduction to Multilevel Modeling: Fitting and Interpretation of Models"
institute: "Princeton University"
author: "Jason Geller, Ph.D. (he/him/his)"
date:  'Updated:`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
      background-image: url("lover.png")
      background-size: cover
      
---
```{r xaringan-extra-styles, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=5, fig.retina=3,
  out.width = "80%",
  tidy.opts=list(width.cutoff=80),tidy=TRUE, 
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  fig.show = TRUE,
  hiline = TRUE
)
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_solarized_dark(
  header_font_google = google_font("Work Sans"),
  header_h1_font_size = "36px",
  header_color = "black",
  text_font_google = google_font("Work Sans"),
  text_font_size = "28px",
  text_color = "black", 
  background_color = "white", 
  code_font_google = google_font("Share Tech Mono"),
  extra_css = list(
    ".remark-slide-content h2" = list(
      "margin-top" = "2em",
      "margin-bottom" = "2em"
    ),
    .big = list("font-size" = "150%"),
    .small = list("font-size" = "75%"),
    .subtle = list(opacity = "0.6"),
    ".countdown-has-style h3, .countdown-has-style h3 ~ p, .countdown-has-style h3 ~ ul" = list(
      "margin" = "0"
    ),
    ".countdown-has-style pre" = list(
      "margin-top" = "-10px"
    ),
    "p .remark-inline-code" = list(
      "background-color" = "white",
      "padding" = "2px 2px",
      "margin" = "0 -2px"
    ),
    blockquote = list("margin-left" = 0),
    "em" = list(color = "#2aa198")
  ),
)
```

```{r, echo=FALSE}
library(parameters)
library(effectsize) 
library(lme4)
library(papaja)
library(tidyverse)
library(performance)
library(see)
library(equatiomatic)
library(broom.mixed)
library(afex)
library(kableExtra)
library(broom)
library(report)
library(emmeans)
library(flextable)
library(huxtable)
library(skimr)
library(scales)
library(sjPlot)
library(papaja)
library(moderndive)
library(tidyverse)
library(fivethirtyeight)
library(broom)
library(ggdist)
```

# Probablity in Logistic Regression

- Categorical Probabilities

```{r, eval=FALSE}

# gender 
# young men
plogis(b0 + b1 * 0) # get prob for males
# young women
plogis(b0 + b1 * 1)# get prob for females
```


- Continuous Probabilities

```{r, eval=FALSE}
# take intercept and add slope for factor of interest and sub to get effect specific prob

data=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/14-Logistic_Regression/data/gss.csv")

relig = glm(religious.attend~sex+age+ses+premarital.sex, data=data1, family="binomial")


plogis(b0 + b1(premartrial.sex)) - plogis(b0)


```

---
# Notation 

- Greek letters denote the fixed effect model parameters that will be estimated
  - e.g., $\alpha_0, \alpha_1, \beta_0, \beta_1$
  
- English letters denote the preliminary effects at lower levels that will not be estimated directly

  - e.g. $a_i, b_i$ 

  - i (individual) and j (group-level)

- $\sigma$ and $\rho$ denote variance components that will be estimated 

- $\epsilon_{ij}, u_i, v_i$ denote error terms 
---
class: middle

# How to run MLM
---
# Basic MLMs

- Same as GLM in how fixed effects are specified

- MLM extras are in the random effects

  - Random intercept and/or
  - Random slope

---
# Data

- Brown (2021) (*article on course website*)

  - 55 participants and 533 items
  
  - Effect of audio and audio-visual elements on intelligibility of words
  
    - https://twitter.com/juliafstrand/status/997528489984131072

- DV: Reaction time
- IV: Modality (audio vs. audio-visual)
  
```{r, echo=FALSE}  
figuredata<- read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/15-MLM/data/figure_data.csv")

figuredata$PID <- as.factor(figuredata$PID)
```

```{r}
rt_data <- read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/15-MLM/data/rt_dummy_data.csv")

```
---
# Crossed Random Effects Model

```{r, echo=FALSE,fig.align='center',out.width="60%"}
knitr::include_graphics("images/2crossed.png")
```
---
# Data Organization


.pull-left[
- Data Structure

  - Long vs. wide

    - MLM analysis requires data in long format
]

.pull-right[
```{r, echo=FALSE, fig.align='center', out.width="100%"}
knitr::include_graphics("images/pivot_longer.png")
```
]
---
# Data Organization

.pull-left[

- Data Structure

  - Long vs. wide

    - MLM analysis requires data in long format
]

.pull-right[ 
```{r, echo=FALSE}

tibble(rt_data)

```
]
---
# Centering

- You must ensure that the zero value for each predictor is meaningful before running the model

  - Categorical variables:

        - Effect-coding or contrast-coding  
        
  - Continuous Predictors:

        - In MLM, there are two ways to center, by the grand mean or the group mean

---
# Group- vs. Grand-Mean  Centering

- Grand-mean centering: $x_{ij} - x$

  - Variable represents each observationâ€™s deviation  from everyoneâ€™s norm, regardless of group

- Group-mean centering: $x_{ij} - x_j$

  - Variable represents each observationâ€™s deviation from their groupâ€™s norm
  
---
# Group- vs. Grand-Mean  Centering

- Level 1 predictors

  - Grand-mean center

     - **Include means of level 2**  
     - Allows us to directly test within-group effect
    
  - Group-mean center 
    - Level 1 coefficient will always be with within-group effect, regardless of whether the group means are included at Level 2 or not
    - If level 2 means included, coefficient represents the between-groups effect
   

.footnote[.small[https://centerstat.org/centering/]]
---
# Group Mean Center in R
```{r, eval=FALSE}

library(datawizard) #easystats 

# how to group mean center 
d <- d %>% 
  # Grand mean centering (CMC)
  mutate(iv.gmc = iv-mean(iv)) %>%
  # Person mean centering (more generally, centering within cluster)
  group_by(id) %>% 
  mutate(iv.cm = mean(iv),
         iv.cwc = iv-iv.cm) %>%
  ungroup %>%
  # Grand mean centering of the aggregated variable
  mutate(iv.cmc = iv.cm-mean(iv.cm))
# data wizard way
x <- demean(x, select=c("x"), group="ID") #gets within-group cluster

```
---
# Estimation: ML and REML

- Two flavors of maximum likelihood
  
  - Maximum Likelihood (ML or FIML)
    
    - Jointly estimate the fixed effects and variance components using all the sample data
    - Can be used to draw conclusions about fixed and random effects
  
    - Issue: Fixed effects are treated as known values when estimating variance components
    
      - Results in biased estimates of variance components (especially when sample size is small)
---
# ML and REML

- Restricted Maximum Likelihood (REML)

  - Estimate the variance components using the sample residuals not the sample data
  
  - It is conditional on the fixed effects, so it accounts for uncertainty in fixed effects estimates. This results in unbiased estimates of variance components
---
# ML or REML? 

- Research has not determined one method absolutely superior to the other

- **REML** (`REML = TRUE`; default in `lmer`) is preferable when:
  - the number of parameters is large or primary, or 
  - Primary objective is to obtain estimates of the model parameters 

- **ML** (`REML = FALSE`) <u>must</u> be used if you want to compare nested fixed effects models using a likelihood ratio test (e.g., a drop-in-deviance test)

  - For REML, the goodness-of-fit and likelihood ratio tests can only be used to draw conclusions about variance components 

<br> 

.footnote[.small[Source: Singer, J. D. & Willett, J. B. (2003). *Applied longitudinal data analysis: Modeling change and event occurrence*. Oxford university press.]]
---
ML or REML?

- What would we use if we wanted to compare the below models?

```{r eval=FALSE}

x= lmer(DV ~ IV1 + IV2 (1|ID))

y= lmer(DV ~ IV1*IV2 + (1|ID))

```

---
ML or REML?

- What would we use if we wanted to compare the below models?

```{r eval=FALSE}

x = lmer(DV ~ IV1 + IV2 + (IV2|ID))

y = lmer(DV ~ IV1*IV2 + (1|ID))

```

---
# Model 

- Intercept-only model

$$
\begin{aligned}
  \operatorname{RT}_{i}  &\sim N \left(\alpha_{j[i]}, \sigma^2 \right) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for PID j = 1,} \dots \text{,J}
\end{aligned}
$$

```{r}
#lme4 install
#afex mixed

m0<-lmer(RT ~ 1 + (1|PID), data=rt_data) #baseline
```
---
# Interclass Correlation (ICC) 

- ICC is a standardized way of expressing how much variance is due to clustering/group 


    - Ranges from 0-1


- Also, can be interpreted as correlation among observations within cluster/group 


- If ICC is sufficiently low (i.e.,  $\rho$ < .1), then you donâ€™t have to use MLM! *BUT YOU PROBABLY SHOULD ðŸ™‚*
  
---
# Calculating ICC

- Run baseline (null) model

- Get intercept variance and residual variance

$$\mathrm{ICC}=\frac{\text { between-group variability }}{\text { between-group variability+within-group variability}}$$

$$ICC=\frac{\operatorname{Var}\left(u_{0 j}\right)}{\operatorname{Var}\left(u_{0 j}\right)+\operatorname{Var}\left(r_{i j}\right)}=\frac{\tau_{00}}{\tau_{00}+\sigma^{2}}$$

```{r, echo=TRUE}
summary(m0)$varcor # get variance
# Get ICC for model
model_performance(m0)$ICC
```
---
# 2 Level-2 Variables

```{r}
m0<-lmer(RT ~ 1 + (1|PID) + (1|stim), data=rt_data) #baseline
summary(m0)$varcor # get variance
# Get ICC for model
model_performance(m0)$ICC

```
$$\frac{\sigma^{2}_{subj}+\sigma^{2}_{item}}{\sigma^{2}_{subj}+\sigma^{2}_{item}+\sigma^{2}_{res}}$$
---
# Fixed Effect, Random Intercept

$$
\begin{aligned}
  \operatorname{RT}_{i}  &\sim N \left(\alpha_{j[i]} + \beta_{1}(\operatorname{modality}_{\operatorname{Audiovisual}}), \sigma^2 \right) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for PID j = 1,} \dots \text{,J}
\end{aligned}
$$

```{r}

modality<-lmer(RT ~ 1 + modality + (1|PID), data=rt_data, REML=TRUE) # add modality

```
---
# Fixed Effect, Random Intercepts (PID and Stim) Model

$$
\begin{aligned}
  \operatorname{RT}_{i}  &\sim N \left(\alpha_{j[i],k[i]} + \beta_{1}(\operatorname{modality}_{\operatorname{Audiovisual}}), \sigma^2 \right) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for stim j = 1,} \dots \text{,J} \\
    \alpha_{k}  &\sim N \left(\mu_{\alpha_{k}}, \sigma^2_{\alpha_{k}} \right)
    \text{, for PID k = 1,} \dots \text{,K}
\end{aligned}
$$

```{r}

modality_pid_item<-lmer(RT ~ 1 + modality + (1|PID) + (1|stim), data=rt_data, REML=TRUE)

```
---
# Fixed Effects, Random Slopes Only Model (Modality)

- Here we add random slopes for `modality` by `PID` and `Stim`

  - 0 instead of 1 eliminates random correlation between intercept and slope
  
  - Random slopes but no random intercepts

```{r}
modality_slope<-lmer(RT ~ 1 + modality + (0+modality|PID) + (0+modality|stim), data=rt_data, REML=TRUE)

```
---
# Fixed Effects Random Slopes (Modality) and Intercpets (PID and Stim) Model

```{r}
modality_item_mod_slope<-lmer(RT ~ 1 + modality + (1+modality|PID) + (1+modality|stim), REML=TRUE, data=rt_data) # fit with different optimizer

```
---
# Convergence Warnings

- Pay attention to these warnings! 

  - Indicates that something went wrong during estimation procedure

- Solutions:

  - Try a different optimizer
  
```{r, eval=FALSE}

#compare which optimizers converge and dont converge
all_fit(modality_item_mod_slope)

```
---
# Convergence Warnings

  - Remove the correlations between random effects, if any
  
  - If that doesnâ€™t converge, remove the by-items slopes for one factor (which explains the least variance) first 
  
  - If that doesnâ€™t converge, remove the remaining by-items slopes
---
# Maximal Model: Fixed Effect Random Intercepts (PID and Stim) and Slopes Model
$$
\begin{aligned}
  \operatorname{RT}_{i}  &\sim N \left(\alpha_{j[i],k[i]} + \beta_{1j[i],k[i]}(\operatorname{modality}_{\operatorname{1}}), \sigma^2 \right) \\    
\left(
  \begin{array}{c} 
    \begin{aligned}
      &\alpha_{j} \\
      &\beta_{1j}
    \end{aligned}
  \end{array}
\right)
  &\sim N \left(
\left(
  \begin{array}{c} 
    \begin{aligned}
      &\mu_{\alpha_{j}} \\
      &\mu_{\beta_{1j}}
    \end{aligned}
  \end{array}
\right)
, 
\left(
  \begin{array}{cc}
     \sigma^2_{\alpha_{j}} & \rho_{\alpha_{j}\beta_{1j}} \\ 
     \rho_{\beta_{1j}\alpha_{j}} & \sigma^2_{\beta_{1j}}
  \end{array}
\right)
 \right)
    \text{, for stim j = 1,} \dots \text{,J} \\    
\left(
  \begin{array}{c} 
    \begin{aligned}
      &\alpha_{k} \\
      &\beta_{1k}
    \end{aligned}
  \end{array}
\right)
  &\sim N \left(
\left(
  \begin{array}{c} 
    \begin{aligned}
      &\mu_{\alpha_{k}} \\
      &\mu_{\beta_{1k}}
    \end{aligned}
  \end{array}
\right)
, 
\left(
  \begin{array}{cc}
     \sigma^2_{\alpha_{k}} & \rho_{\alpha_{k}\beta_{1k}} \\ 
     \rho_{\beta_{1k}\alpha_{k}} & \sigma^2_{\beta_{1k}}
  \end{array}
\right)
 \right)
    \text{, for PID k = 1,} \dots \text{,K}
\end{aligned}
$$

```{r}

modality_item_mod_slopes<-lmer(RT ~ 1 + modality + (1+ modality|PID) + (1+ modality|stim),control=lmerControl(optimizer="bobyqa"),  data=rt_data)
```
---
# Syntax

```{r, echo=FALSE, fig.align='center', out.width="80%"}
knitr::include_graphics("images/lmesyntax.png")
```
---
class: middle

# Model Comparisons
---
# Model Comparisons

- `Keep it maximal`

  - Whatever can vary, should vary 

  - Only when there is convergence issues should you remove terms
  
-**Decreases Type 1 error**
  
.footnote[.small[Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of memory and language, 68(3), 10.1016/j.jml.2012.11.001. https://doi.org/10.1016/j.jml.2012.11.001]]
---
# Model Comparisons

Top-down procedure:

- Fit a maximal model

- Sort out the random effects

- Sort out fixed effects

- Once you arrive at the final model present it using REML estimation

- Can use `anova` function
---
class: middle

# Interepreting MLM Models

---
# Full Model

```{r}

modality_item_mod_slopes<-lmer(RT ~ 1 + modality + (1+ modality|PID) + (1+ modality|stim),control=lmerControl(optimizer="bobyqa"),  data=rt_data)

```

`RT ~ 1 + modality`: Represents the fixed effects + intercept 

--

`(1+ modality|PID) + (1+ modality|stim)`: Represents the error terms and associated variance components

---
# Testing Multilevel Assumptions

- Linearity
- Normality
- Homoscedasticity
- Collinearity 
- Outliers

- ~~Missingness~~
- ~~Independence~~

```{r, eval=FALSE}

check_model(model)# test assumptions

```
---
# Tidy output 

Display results using the `tidy` function from the **broom.mixed** package. 

```{r eval = F}
library(broom.mixed)
```

- Get fixed effects only 

`tidy(modality_item_mod_slopes) %>% filter(effect == "fixed")`

- Get errors and variance components only

`tidy(modality_item_mod_slopes) %>% filter(effect == "ran_pars")`

---
# Fixed Part

```{r}
library(broom.mixed)

tidy(modality_item_mod_slopes) %>% filter(effect == "fixed")
```
- Default behavior is leave out *p*-values (Doug Bates doesn't like them)

- Install `lmerTest` to include *p*-values

---
# Denomitator Degrees of Freedom

- Degrees of freedom (denominator) can be assessed with several methods:

  - Asymptotic (1.96) (**default** behavior lme4)

  - Satterwaithe (default when install `lmerTest` and then run `lmer`)

  - Kenward-Rogers
---
# Using `emmeans`

- Get factor means and contrasts

```{r} 

library(emmeans)

emmeans(modality_item_mod_slopes, specs = "modality") # grabs means for each level of modality

emmeans(modality_item_mod_slopes, specs = "modality") %>%
  pairs() # use this to get pariwise compairsons between levels of factors
```

---
# Random Effects

```{r}

tidy(modality_item_mod_slopes) %>% filter(effect == "ran_pars")

```

---
# Plotting Random Effects

```{r}
plot_model(modality, type = "re", terms = "PID")
```
---
# Effect Size

- Highly debated

  - Report Pseudo-$R^2$ for marginal (fixed) and conditional model (random) parts
  
  - Transform f to $\eta_p^2$ (*when using afex::mixed)*

```{r, eval=FALSE}
#easystats
r2(modality_item_mod_slopes)
 #Generate R-squared measures for that model:

model_performance(modality_item_mod_slopes)
```

---
# Reporting Results

- LRT

  - Do not use if # levels of random effect(s) < 50

A likelihood-ratio test indicated that the model including modality provided a better fit for the data than a model without it, Ï‡2(1) = 32.39, p < .001. Examination of the summary output for the full model indicated that response times were on average an estimated 83 ms slower in the audiovisual relative to the audio-only condition, $\beta = 83.18, SE = 12.58, t = 6.62, p < .001$

```{r, eval=FALSE}
library(afex)
m4 <- mixed(RT ~ 1 + modality+  (1+modality|PID) + (1+ modality|stim), data = rt_data, method = "LRT")
```
---
# Lmer Model 

- Summary report

`r report(modality_item_mod_slopes)`

---
# F-values

- F-test/ANOVA

A linear mixed model was performed using the  function `mixed` from `afex`. The analysis indicated a main effect of modality, $F = 43.75(1, 52.09), p < .001, \eta_p^2 = 0.46$.Examination of the summary output for the full model indicated that response times were on average an estimated 83 ms slower in the audiovisual relative to the audio-only condition, $\beta = 83.18, SE = 12.58, t = 6.62, p < .001$ 

```{r, eval=FALSE}
# can use F values from this to grab an estimated effect size
F_to_eta2(43.75,1,  52.09)

```


```{r, eval=FALSE}
# get output with F values
m4 <- mixed(RT ~ 1 + modality+  (1+modality|PID) + (1+ modality|stim), data = rt_data)
```
---
# Plotting Results

- Plot model estimates (using emmeans or modelbased::estimate_means) + raw (aggregate group) data

.pull-left[
```{r, fig.align='center', out.width="100%"}
library(modelbased)

rt_data$modality<-as.factor(rt_data$modality)

modality_item_mod_slopes<-lmer(RT ~ 1 + modality + (1+ modality|PID) + (1+ modality|stim),control=lmerControl(optimizer="bobyqa"),  data=rt_data)

mod_plot <- modality_item_mod_slopes %>%
  estimate_means("modality") %>%
  as.data.frame()
  
```
]

.pull-right[
```{r, echo=FALSE, fig.align='center', out.width="100%"}
library(see)

rt_data_mean <- rt_data %>%
  group_by(PID, modality) %>%
  summarise(mean_RT=mean(RT, na.rm=TRUE)) %>% 
  ungroup()

ggplot(rt_data_mean, aes(x = modality, y = mean_RT)) + 
  geom_violin(aes(fill = modality), color = "white") +
  geom_jitter2(width = 0.05, alpha = 0.5, size=5) +
  # Add pointrange and line from means
  geom_line(data = mod_plot, aes(y = Mean, group = 1), size = 1) +
  geom_pointrange(
    data = mod_plot,
    aes(y = Mean, ymin = CI_low, ymax = CI_high),
    size = 1,
    color = "white"
  ) +
  # Improve colors
  scale_fill_material() +
  theme_modern() + 
  ggtitle("Modality Effect", subtitle = "White dots represent model mean and error bars represent 95% CIs. Black dots are group level means for each person")

```
]

---
# Describing a MLM Analysis

- The type of model you conducted

  - How many levels?
  
    - Your "nesting" variable
    
  - Which effects were random

- Your DV, IVs, and covaritaes (full fixed effect specification)

- Method of estimating degrees of freedom (e.g., Kenward-Rogers, asymptotic)

- ICC of the model
---
# Example Reporting

As shown in Figure 1, teacher support had a large positive relationship with behavioral improvement, b = 0.26, SE = 0.05, t(54) = 4.83, p < .01, R2 = .33. The amount of money invested in a school had no effect on behavioral improvement, b = 0.01, SE = 3.01E-3, t(66) = 1.99, p = .05, R2 = .004. The amount of money invested in a school also did not moderate the relationship between teacher support and behavioral improvement, b = -2.06E-4, SE = 4.08E-3, t(62) = -0.05, p = .96, R2 =.002

---
# Example Reporting

A 2-level multilevel model was used to analyze these data, because classrooms were nested within schools. Behavioral change was modeled as a function of teacher support, money invested in the school, and the interaction between these variables. Because the interaction between teacher support and money were measured at different levels, we modeled a random slope for the Level 1 predictor, teacher support, in addition to a random intercept (Aguinis, Gottfredson, & Culpepper, 2013). The model was estimated with an unstructured covariance matrix and Satterthwaite degrees of freedom using the lme4 (Pinheiro, Bates, DebRoy, Sarkar, & R Core Team, 2015) and lmerTest (Kuznetsova, Brockhoff, & Christensen, 2017) packages in R 4.0.3 (R Core Team, 2020). The ICC for the model suggested that behavioral change was mildly clustered within schools, ICC = .10.

---
# Power

- Simulation

  - Simulate new data
    - `faux`(https://debruine.github.io/faux/articles/sim_mixed.html)
    
  - Use pilot data (what I would do)
    - `mixed` (https://link.springer.com/article/10.3758/s13428-021-01546-0)
    - `simr`
    
    
---
# Activity

- Run two MLMs 

- Run a random random intercept model and a random slopes and intercepts model

  - Use `behaviour.improvement` as (DV) and `teaching support` as IV 
  
    - `school.id` as random effect

```{r}
library(lme4)
library(lmerTest)
library(emmeans)

data <- read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/15-MLM/data/Basic_MLM_Data.csv")

glimpse(data)
```
---
# Plotting

```{r, echo=FALSE,  fig.align='center', out.width="100%"}
mod=lmer(behaviour.improvement~teacher.support + (1|school.id), data=data)

mod1=lmer(behaviour.improvement~teacher.support + (1+teacher.support|school.id), data=data)

plot_model(mod1, type = "eff", terms = "teacher.support")
```

---
# Acknowledgements

.footnote[.small[Elizabeth Page-Gould materials on OSF: https://osf.io/q6wnd]]
