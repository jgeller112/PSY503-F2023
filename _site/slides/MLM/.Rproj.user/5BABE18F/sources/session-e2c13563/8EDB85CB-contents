---
title: "Lab 9: Clustering Ans"
subtitle: "Lab 9"
editor: visual
execute: 
  message: false
  warning: false
---s
---

## Lab 9 - Clustering

## Instructions:

-   If you are fitting a model, display the model output in a neatly formatted table. (The \`tidy\` and \`kable\` functions can help!).

-   If you are creating a plot, use clear labels for all axes, titles, etc.

-   Commit and push your work to GitHub regularly, at least after each exercise. Write short and informative commit messages.

When you're done, we should be able to knit the final version of the QMD in your GitHub as a HTML.

## Data

-   For this lab, we will reproduce the results of Reilly et al. (2023; Experiment 1). In Experiment 1, they were interested in whether clusters segregate by smell in a patient with anosmia (loss of smell). Do not worry about any of the statistical tests performed.

Reilly, J., Finley, A. M., Kelly, A., Zuckerman, B., & Flurie, M. (2021). Olfactory language and semantic processing in anosmia: A neuropsychological case control study. *Neurocase*, *27*(1), 86--96. <https://doi.org/10.1080/13554794.2020.1871491>

-   The data and analysis scripts can be found on OSF.

## Hierarchical clustering

-   Run a hierarchical cluster analysis as done in Reilly et al. (2021; Experiment 1). Please include both dendrograms. Do your dendrograms have similar pattern?

    -   We read in the data from OSF and tidy up the data.

    ## P01 Clustering

    ```{r}
    p01<-read_csv("https://osf.io/694mz/download")

    head(p01)

    p01 <- as.data.frame(p01)

    rownames(p01)<- p01$...1

    p01 <- p01[,-1]

    p01_dist <- dist(p01, method="euclidean")

    head(p01_dist)

    ```

    ```{r}

    library(dendextend)
    library(factoextra)


    clust_p01 <- hclust(p01_dist, method="complete")

    fviz_dend(clust_p01)

    ```

    -   

    -   Tidy up the data from the OSF

    ```{r}
    # tidy table


    d <- read_csv("https://osf.io/zygvh/download")

    mturk<- d %>% group_by(Word, Dimension) %>% summarise(Rating=mean(Rating, na.rm = TRUE)) %>% pivot_wider(names_from = "Dimension", values_from = "Rating" )

    mturk <- as.data.frame(mturk)

    rownames(mturk)<- mturk[,1]

    # get rid of word col
    mturk <- mturk %>%
      select(-Word)

    mturk_dist <- dist(mturk, method = "euclidean")

    ```

    ```{r}

    library(dendextend)
    library(factoextra)

    clust_mturk <- hclust(mturk_dist)

    fviz_dend(clust_mturk)

    ```

    ## MTurk: Elbow, Silhouette, Gap

    ```{r}
    # Plot cluster results
    p1 <- fviz_nbclust(mturk, FUN = hcut, method = "wss", 
                       k.max = 10) +
      ggtitle("(A) Elbow method")
    p2 <- fviz_nbclust(mturk, FUN = hcut, method = "silhouette", 
                       k.max = 10) +
      ggtitle("(B) Silhouette method")

    p3 <- fviz_nbclust(mturk, FUN = hcut, method = "gap_stat", 
                       k.max = 10, nboot=100) +
      ggtitle("(C) Gap statistic")

    gridExtra::grid.arrange(p1, p2,p3,  nrow = 1)


    ```

    -   All together this suggests 2-3 clusters for Mturk sample.

    ## P01: Elbow, Silhouette, Gap

    ```{r}
    # Plot cluster results
    p1 <- fviz_nbclust(p01, FUN = hcut, method = "wss", 
                       k.max = 10) +
      ggtitle("(A) Elbow method")
    p2 <- fviz_nbclust(p01, FUN = hcut, method = "silhouette", 
                       k.max = 10) +
      ggtitle("(B) Silhouette method")

    p3 <- fviz_nbclust(p01, FUN = hcut, method = "gap_stat", 
                       k.max = 10, nboot=100) +
      ggtitle("(C) Gap statistic")

    gridExtra::grid.arrange(p1, p2,p3,  nrow = 1)


    ```

    -   All together this suggests anywhere from 2-5 clusters for P01

        ## Reilly

        These results are not quite the same. Doing a HAC first, we get clusters ranging from 2-5 for P01 and 2-3 for MTurk sample. The study in question used 3 clusters for P01 and 5 clusters for MTurk. I assume Reilly et al. went with the number of clusters that made sense.

    ## Bootstrapping

    ## Mturk and P01

    ::: callout-warning
    This approach appears to identify too many clusters (small clusters). It is probably not a good idea to use this.
    :::

    ```{r}
    library(easystats)
    #easystats
    n <- n_clusters_hclust(mturk, standardize=FALSE, distance_method = "euclidian", hclust_method = "ward.D2",  iterations = 500)

    plot(n)

    n1 <- n_clusters_hclust(p01, standardize=FALSE, distance_method = "euclidian", hclust_method = "complete",  iterations = 500)

    plot(n1)

    ```

    ```{r}
    #| fig-width: 6
    #| fig-height: 12

    fviz_dend(x = clust_mturk, cex = 0.8, lwd = 0.8, k = 2,
              rect = TRUE, 
              rect_border = "gray", horiz = TRUE, 
              rect_fill = FALSE)

    fviz_dend(x = clust_p01, cex = .8, lwd = 0.8, k = 3,
              rect = TRUE, repel = TRUE, 
              rect_border = "gray",
              horiz = TRUE, 
              rect_fill = FALSE)

    ```

-   Run the same analysis, but choose a different link method. Does this change the interpretation at all? Please provide a dendrogram with the link method you selected.

    ```{r}



    ```

-   Determine the optimal number of clusters for each group using the elbow, silhouette, and gap methods. Do they all agree?

    ```{r}


    ```

-   Perform a bootstrapped hierarchical clustering analysis on both P01 and MTurk samples. Does the number of clusters converge with the \# clusters above?

    ```{r}

    ```

-   Include a color-coded dendrogram for your final selection (use `dendextend`)

## K-means

-   Now perform a k-means cluster analysis. As a starting point, k = \# of clusters decided on above. \Plot a figure of the cluster solution.

    -   We can get the optimal number of clusters by running the `cluster_analysis` function from `easystats`. This is what I did.

        ```{r}

        cluster_analysis(mturk) # 4 clusters

        cluster_analysis(p01) # 3 clusters

        ```

    -   These results suggest the adequate number of clusters for P01 are 3 and Mturk are 4.

-   Use the consensus method `n_clusters` to determine the number of clusters. Include a figure of the new cluster solution.

    -   This returns same number of clusters as above with the `cluster_analysis` function.

        ```{r}
        n_clusters(p01) %>%
          plot()
        n_clusters(mturk) %>%
          plot()
        ```

        ```{r}

        cluster_analysis(mturk) %>% 
          plot()# 4 clusters

        cluster_analysis(p01) %>%
          plot()# 3 cluster
        ```

        ## Write-up

-   Write-up a report and make sure to interpret/name your clusters. If there are any differences between your analysis and theirs, describe them. Additionally, share your thoughts on how the authors shared their data.
