---
title: "PSY 503: Foundations of Statistical Methods in Psychological Science"
subtitle: "More LM: Moderation/Interactions"
institute: "Princeton University"
author: "Jason Geller, Ph.D. (he/him/his)"
date:  'Updated:`r Sys.Date()`'
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      ratio: 19:11
      countIncrementalSlides: true
      
---
```{r xaringan-extra-styles, echo=FALSE}
library(xaringanExtra)
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)

```

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=9, fig.height=3.5, fig.retina=3,
  out.width = "50%",
  tidy.opts=list(width.cutoff=60),tidy=TRUE, 
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE,
  fig.show = TRUE,
  hiline = TRUE
)
hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_solarized_dark(
  header_font_google = google_font("Work Sans"),
  header_h1_font_size = "36px",
  header_color = "black",
  text_font_google = google_font("Work Sans"),
  text_font_size = "25px",
  text_color = "black", 
  background_color = "white", 
  code_font_google = google_font("Work Sans"),
  extra_css = list(
    ".remark-slide-content h2" = list(
      "margin-top" = "2em",
      "margin-bottom" = "2em"
    ),
    .big = list("font-size" = "150%"),
    .small = list("font-size" = "75%"),
    .subtle = list(opacity = "0.6"),
    ".countdown-has-style h3, .countdown-has-style h3 ~ p, .countdown-has-style h3 ~ ul" = list(
      "margin" = "0"
    ),
    ".countdown-has-style pre" = list(
      "margin-top" = "-10px"
    ),
    "p .remark-inline-code" = list(
      "background-color" = "white",
      "padding" = "2px 2px",
      "margin" = "0 -2px"
    ),
    blockquote = list("margin-left" = 0),
    "em" = list(color = "#2aa198")
  ),
)
```


```{r, echo=FALSE}
library(parameters)
library(effectsize) 
library(papaja)
library(tidyverse)
library(performance)
library(see)
library(equatiomatic)
library(kableExtra)
library(stargazer)
library(broom)
library(easystats)
library(interactions)
library(report)
library(emmeans)
library(flextable)
library(huxtable)
library(skimr)
library(papaja)
library(moderndive)
library(Superpower)
```
# Outline

- Testing interactions/moderation analysis

  - Categorical by Continuous
  - Continuous by Continuous
  - Categorical by Categorical (Monday)
    
---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure + water)

```

---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure +  water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("sun-water.bmp")
```
---
# Interactions
```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure * water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("plant-sun.png")
```
---
# Interactions

```{r, eval=FALSE}

lm(plant_growth ~ sun_exposure * water)

```

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("sun-inter.png")
```
---
# What is a moderator?

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("moderation1.png")
```
$$Y=\beta_{0}+\beta_{1}*X+\epsilon$$
---
# What is a moderator?

- A moderator variable Z is a variable that alters the strength of the relationship between X and Y

```{r, echo=FALSE, fig.align='center', out.width="90%"}

knitr::include_graphics("moderation2.png")
```

---
# What Do Interactions Look Like?

```{r, echo=FALSE, fig.align='center', out.width="90%"}

knitr::include_graphics("types-of-interaction-flat.png")
```
---
class: middle

# Categorical x Continuous Interactions

---
# Today's Dataset

- Student evaluations for a sample of 463 courses taught by 94 professors from the University of Texas at Austin

- Six students rated the professors' physical appearance 

```{r}
evals_agegend=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/evals.csv")
evals1= evals_agegend %>%
dplyr::select(ID, score, age, gender)
```

```{r, echo=FALSE}
summary(evals)
```
---
# Research Question

- Does Age and Sex (Males, Females) of the instructor influence instructor ratings?

    - DV: Evals
    - IV:
        - Age 
        - Gender
        - Age*Gender Interaction
---
# Scatterplot

```{r, fig.align='center', out.width="100%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)
```

---
# How to Conduct Moderation Analysis?

- Moderation analysis can be conducted by adding one or multiple interaction terms in a regression analysis

Z is a moderator for the relation between  X and  Y, we can fit a regression model

$$\begin{eqnarray*} 
Y & = & \beta_{0}+\beta_{1}*X+\beta_{2}*Z+\beta_{3}*X*Z+\epsilon\\ & = & \begin{cases} \beta_{0}+\beta_{1}*X+\epsilon & \mbox{For females}(Z=0)\\ \beta_{0}+\beta_{2}+(\beta_{1}+\beta_{3})*X+\epsilon & \mbox{For males}(Z=1) \end{cases} \end{eqnarray*}$$

- When Z=0 (females),the effect of X on Y is β1+β3∗0=β1

- When Z=1 (males), the effect of X on Y is β1+β3∗1 

---
# Steps for Moderation Analysis

A moderation analysis typically consists of the following steps:

1. Compute the interaction term XZ=X*Z 

2.  Fit a multiple regression model with X, Z, and XZ as predictors

3.  Test whether the regression coefficient for XZ (interaction) is significant

4.  If so, interpret the moderation effect (ignore main effects)

5.  Display the moderation effect graphically
---
# Steps for moderation analysis

-  Compute the interaction term XZ=X*Z

  - Center continuous variables

    - Centering solves two problems: 
    
      - Interpretation
      
      - Multicollinearity

```{r}
evals_interact <- evals1 %>%
  mutate(age_c=datawizard::center(age),gender_trt=ifelse(gender=="female", 0, 1), inter=age_c*gender_trt)
```
---
# Steps for moderation analysis

-  Fit a multiple regression model with X, Z, and XZ as predictors

```{r}
lm(evals_interact$score~age_c*gender_trt, data=evals_interact) %>%
  tidy()
```
---
# Steps for moderation analysis

- Test whether the regression coefficient for XZ is significant

```{r}
lm(score~age_c*gender_trt, data=evals_interact) %>%
  tidy()
```
---
# Interpretation

$$\hat{Y}= b_0 + b_1 X + b_2 Z + b_3 X*Z$$

- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$: The offset/difference in the intercept for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$: The interaction of $X$ and $Z$, the offset in slope for $Z$ for a one-unit increase in $X$ (or vice versa)
---
# Interpretation

```{r}
lm(score~age_c*gender_trt, data=evals_interact) %>%
 tidy()
```
$b_0$ = 
$b_{age}$ = 
$b_{gender}$ = 
$b_{age}*{male}$ = 

???

Average Score for females is at average age 

age_c: slope of age for z = 0 (females) b0 + b1 + b2(0) + b3 (0)

gender M: slope offset for difference between males and females at average age

age_c*gender: the offset slope males

---
# Moderation: Simple Slopes

- If the interaction is significant, then you usually ignore the other individual effects (age and gender)

- So what do I do if my interaction is significant? **A simple slope analysis**

---
# Main vs. Simple Effects (slopes)

- Main Effects

  - Coefficients that do no involve interaction terms
  
  - Comparison of marginal means

.pull-left[

```{r, echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("marginalMean9.png")

```
]

.pull-right[
$$\hat{Y}= b_0 + b_1 X + b_2 Z$$

-$b_0$: The intercept, or the predicted outcome when  X and Z are 0
-$b_1$: The slope (or main effect) of X ; for a one unit change in  the predicted change in Y
-$b_2$: The slope (or main effect) of Y ; for a one unit change in  the predicted change in Y
]
---
# Main vs. Simple effects (slopes)

- Simple Effects

  - Comparison of cell means

$$\hat{Y}= b_0 + b_1 X + b_2 Z + b_3 X*Z$$
- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$:The simple effect or slope of $Z$, for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$:The interaction of $X$ and $Z$, the change in the slope of $X$ for a one-unit increase in $Z$ (or vice versa)

---
# Steps for Moderation Analysis

- Obtain simple slopes

  - When a continuous independent variable interact with a moderating variable, its slope at a particular level of the moderating variable

  - Test if slope $\neq$ 0 

```{r}
#hello to our friend emmeans 
#library(emmeans)
d=lm(score~age_c*gender_trt, data=evals_interact)

emtrends(d, ~ gender_trt, var="age_c") #simple slopes
```
---
# Simple Slopes

```{r}

sim_slopes(d, pred=age_c, modx=gender_trt)

```
---
# Steps for Moderation Analysis

- Difference in slopes

  - *Testing simple slopes is not the same thing as testing their difference*

```{r}
d=lm(score~age_c*gender_trt, data=evals_interact)

emtrends(d, pairwise ~ gender_trt, var="age_c")
```
---
# Interactions 

- You should only be following up interactions if significant! 

```{r, echo=FALSE, fig.align='center', out.width="80%"}

knitr::include_graphics("gelman.png")

```

---
# Visualize 

```{r, fig.align='center', out.width="90%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)

```

---
# Parallel Slopes

- Parallel slopes models still allow for different intercepts but force all lines to have the same slope.

```{r, fig.align='center', out.width="80%"}
ggplot(evals1, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_parallel_slopes(se = FALSE)
```
---
# Parallel Slopes

```{r}
main<-lm(score~age_c + gender_trt, data=evals_interact) 
inter<- lm(score~age_c*gender_trt, data=evals_interact)

anova(main, inter)
```
---
# Parallel Slopes

<br>
<br>

.pull-left[

```{r, echo=FALSE, fig.align='center', out.width="100%"}
ggplot(evals_interact, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_smooth(method = "lm", se = FALSE)
```

]
.pull-right[

```{r, echo=FALSE, fig.align='center', out.width="100%"}
ggplot(evals_interact, aes(x = age, y = score, color = gender)) +
  geom_point() +
  labs(x = "Age", y = "Teaching Score", color = "Gender") +
  geom_parallel_slopes(se = FALSE)
```
]
---
# Practice In-Class Activity

- Pick a new categorical and continuous variable to examine if they interact with teaching evals

- Go through the steps outlined in the lecture

- Be ready to talk as a group about what you ran and found

```{r}

evals_agegend=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/evals.csv")

```
---
# Today (11/14)

- Weekly Q & A

- More interactions! 

---
# Weekly Qs

- Main Effects and Simple Effects

  - Main Effect: The effect of one factor on the dependent variable

  - Interaction: The effect of one factor depends on levels of an additional variable

      - Simple effects/simple slopes
      
            - Comparison of cell means 
  
           - Follows up any statistically significant interaction
            - Helps break down interaction to tell us where the interaction is happening

---

```{r}
d=lm(score~age_c*gender_trt, data=evals_interact)
d
emtrends(d, pairwise ~ gender_trt, var="age_c")
```

---
# Weekly Qs

- Effect Sizes

   - *d* for the difference (t-test)

      - For specific effects $\eta_p^2$ 

```{r}
library(effectsize)
inter<- lm(score~age_c*gender_trt, data=evals_interact)
effectsize::eta_squared(inter) # partial eta squared
```
---
# Multicollinearity

```{r, echo=FALSE}
data(state)

data=as.data.frame(state.x77)

data_c <- data  %>%
  mutate(murder_c=datawizard::center(Murder), income_c=datawizard::center(Income), murder_z=scale(murder_c), income_z=scale(income_c), life=scale(`Life Exp`))

not_c<- lm(`Life Exp`~Murder*Income, data=data_c )
c<- lm(`Life Exp`~murder_c*income_c, data=data_c )
```

```{r}
lm(`Life Exp`~Murder*Income, data=data_c ) %>%
check_collinearity()

```

---
```{r}

c %>% 
  check_collinearity()
```
---
class: middle

# When in doubt, center!

---
# Weekly Qs

- Standardizing Data vs. Standardizing Coefs

```{r}
z <- lm(`Life Exp`~scale(Murder)*scale(Income), data=data_c) %>%
tidy()
z
```

---
# Weekly Qs

- Standardizing Data vs. Standardizing Coefs

```{r}
z_coef<-lm(`Life Exp`~murder_c*income_c, data=data_c) %>%
 standardize_parameters(
include_response=FALSE) # by default standardizes response/outcome

z_coef
```
---
# Weekly Qs

- Parallel Slopes

  - Way to see if interaction term is warranted

```{r}
main<-lm(score~age_c + gender_trt, data=evals_interact) 

inter<- lm(score~age_c*gender_trt, data=evals_interact)

anova(main, inter)
```

---
# Weekly Qs

- Power Transformations

.pull-left[
  - Box-Cox  
  
    - Is there a transformation that will normalize my data?
    - What is the optimal value of the transformation parameter?

```{r, echo=FALSE, fig.align="center", out.width="50%"}

knitr::include_graphics("power.PNG")
```
]

.pull-right[

```{r, eval=FALSE}
library(MASS)
#run test
boxcox(lm(x ~ 1))
# Exact lambda
lambda <- b$x[which.max(b$y)]
lambda

```
]
---

# Weekly Q 

- Checking heterogeneity assumption

  - Performing this test does not do anything to alpha 
  
  - Differing degrees of heterogeneity can lead to Type 1 error
  
---
class: middle 
# Continuous x Continuous Interactions
---
# Continuous x Continuous Interactions

- Do violent video games make people aggressive? 

    - DV: Aggression
    - IV:
    
        - Callous unemotional traits 
        - Number of hours spent playing video games per week
        - Callous unemotional traits*Number of hours spent playing video games per week
        
- If callous-unemotional traits were a moderator then we're saying that the strength or direction of the relationship between game playing and aggression depends on the strength of callous-unemotional traits

```{r}
# grab dataset from link
moderation_vio=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/moderation.csv")
```

---
# Continuous x Continuous Interactions

- Centering 

  - Can reduce multicollinearity

  - This is because if $X*Z$ creates a line, it means you have added a new predictor (XZ) that strongly correlates with X and Z

```{r}
library(datawizard)
# centering vars
moderation_vio <- moderation_vio %>%
  mutate(vid_games_c=center(Vid_Games), caunts_c=center(CaUnTs))

```
---
# How does this look?

```{r, echo=FALSE, fig.align="center", out.width="100%"}

knitr::include_graphics("interexamp.png")
```
---
# Continuous x Continuous Regression

```{r}
lm(Aggression~ vid_games_c*caunts_c,  data=moderation_vio) %>%
  tidy()
```

???

(Intercept): the intercept, or the predicted outcome when hours = 0 and traits = 0.
 hours: the slope of Hours, for a one unit change in Hours, the predicted change in weight loss at Effort=0. 
triat: the slope of trait, for a one unit change in vio the predicted change in trait at Hours=0.
 hours:effort: the interaction of Hours and Effort, the change in the slope of HRS for every one unit increase in CALLOUSNESS (or vice versa).
 
---
# Interpretation Continuous x Continuous Interactions

- $b_0$: the intercept, or the predicted outcome when  X = 0 and Z=0
- $b_1$: the simple effect or slope of $X$, for a one unit change in $X$ the predicted change in $Y$  at  $Z = 0$
- $b_2$: The simple effect or slope of $Z$, for a one unit change in $Z$ the predicted change in Y  at X  = 0 
- $b_3$:The interaction of $X$ and $Z$, the change in the slope of $X$ for a one-unit increase in $Z$ (or vice versa)

```{r, echo=FALSE}
lm(Aggression~ vid_games_c*caunts_c,  data=moderation_vio) %>%
  tidy()
```
---
# Continuous X Continuous Interactions

- If the Z (moderator variable) was categorical, you would be checking if separate groups (levels) have different slopes for the non-categorical variable

- However, we cant do that with continuous x continuous interactions

---
# Decomposing Continuous X Continuous Interactions: Spotlight Analysis

- For continuous moderator variables, you "create" low, average, and high groups

    - Low groups are people who are one SD below the mean
    
    - Average groups are people are at the mean
    
    - High groups are people who are one SD above the mean 
---
# Moderation: Simple Slopes

- We are examining the interaction between hours of video games and unemotional traits to predict aggression

- Think about which variable you want to know the differences in (i.e., low, average, high)

- So at different levels of callousness, we want to examine the relationship between hours of video game play and aggression
---
# Probing Interactions: Spotlight Analysis

- Low/below mean created by *SUBTRACTING* 1 SD

- High/above mean created by *ADDING* 1 SD

- The rule is that we have to bring them to the middle because we centered so that zero is the middle

```{r}
#create the low and high z score variables 
a <- mean(moderation_vio$caunts_c) + sd(moderation_vio$caunts_c)

at <- mean(moderation_vio$caunts_c)

b <- mean(moderation_vio$caunts_c) - sd(moderation_vio$caunts_c)

```

---
# Spotlight Analysis

```{r}

# create a list for values at a, b, and mean and round them
mylist <- list(caunts_c=c(round(b, 1), round(at,1), round(a, 1)))

# run lm again
d=lm(Aggression~vid_games_c*caunts_c,data=moderation_vio)

# get simple slopes at each level at b a
emtrends(d,~caunts_c, var="vid_games_c", at=mylist)

```
--

- At high levels of callousness, the strength of hours of video games predicting aggression is the strongest, b = 0.43 ... 

---
# Graphing Continuous x Continuous Interactions

```{r, echo=TRUE}
moderation_vio$caunts_clow <- moderation_vio$caunts_c + sd(moderation_vio$caunts_c) #bring them up
moderation_vio$caunts_chigh <- moderation_vio$caunts_c - sd(moderation_vio$caunts_c) #bring them down
modmodellow <- lm(Aggression ~ vid_games_c*caunts_clow, data = moderation_vio)
modmodelhigh <- lm(Aggression ~ vid_games_c*caunts_chigh, data = moderation_vio)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.align='center', out.width="100%"}
library(ggplot2)

cleanup <- theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
modgraph <- ggplot(moderation_vio, aes(vid_games_c, Aggression))
##change Cal to the new moderator label
##change xlab for the new X label
modgraph + 
  xlab("Centered Video Games") + 
  geom_point(color = "gray") +
  geom_abline(aes(intercept = modmodellow$coefficients[1],
                  slope = modmodellow$coefficients[2], 
                  linetype = "-1SD Cal"), size = 1) +
  geom_abline(aes(intercept = d$coefficients[1],
                  slope = d$coefficients[2], 
                  linetype = "Average Cal"), size = 1) +
  geom_abline(aes(intercept = modmodelhigh$coefficients[1],
                  slope = modmodelhigh$coefficients[2], 
                  linetype = "+1SD Cal"), size = 1) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Cal", "Average Cal", "+1SD Cal"),
                        name = "Simple Slope") +
  cleanup 
```
---
# Graphing Continuous x Continuous Interactions

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width="100%"}
library(ggplot2)

cleanup <- theme(panel.grid.major = element_blank(), 
                panel.grid.minor = element_blank(), 
                panel.background = element_blank(), 
                axis.line.x = element_line(color = "black"),
                axis.line.y = element_line(color = "black"),
                legend.key = element_rect(fill = "white"),
                text = element_text(size = 15))
modgraph <- ggplot(moderation_vio, aes(vid_games_c, Aggression))
##change Cal to the new moderator label
##change xlab for the new X label
modgraph + 
  xlab("Centered Video Games") + 
  geom_point(color = "gray") +
  geom_abline(aes(intercept = modmodellow$coefficients[1],
                  slope = modmodellow$coefficients[2], 
                  linetype = "-1SD Cal"), size = 1) +
  geom_abline(aes(intercept = d$coefficients[1],
                  slope = d$coefficients[2], 
                  linetype = "Average Cal"), size = 1) +
  geom_abline(aes(intercept = modmodelhigh$coefficients[1],
                  slope = modmodelhigh$coefficients[2], 
                  linetype = "+1SD Cal"), size = 1) +
  scale_linetype_manual(values = c("dotted", "dashed", "solid"),
                        breaks = c("-1SD Cal", "Average Cal", "+1SD Cal"),
                        name = "Simple Slope") +
  cleanup 
```
---
# Probing Interactions: Simplier Way

- Use `interact_plot` from the `interactions`

```{r, fig.align='center', out.width="80%"}
library(interactions)

interact_plot(d, pred = vid_games_c, modx = caunts_c, interval = TRUE, plot.points = TRUE)

```

---
# Probing Interactions: Johnson-Neyman Plot

.pull-left[

- Is a floodlight analysis on the whole range of the moderator

- Provides an interval (2 points) where the slope of a predictor is not statistically significant across different values of the mediator

```{r, echo=TRUE, warning=FALSE, message=FALSE, fig.align='center', eval=FALSE}
library(interactions)
johnson_neyman(model = d, pred = vid_games_c,
  modx = caunts_c, control.fdr = TRUE) # important bc otherwise does not correct for multiple comparisons
```

]
<br>
<br>
.pull-right[

```{r, echo=FALSE, fig.align='center', out.width="100%", warning=FALSE, message=FALSE, fig.align='center'}

knitr::include_graphics("JNplot.png")
```

]
---
# Moderation: MeMoBootR

- We can use the `MeMoBootR` to complete the entire processing, including data screening for us! 

- You would enter the raw variables, as the centering is completed for you

```{r}
#devtools::install_github("doomlab/MeMoBootR")
library(MeMoBootR)
mod_model <- moderation1(y = "Aggression",
                         x = "Vid_Games",
                         m = "CaUnTs",
                         df = moderation_vio)
```
---
# Moderation: MeMoBootR

```{r}
#data screenin
#mod_model$datascreening$fulldata
#models
#summary(mod_model$model1)
#mod_model$interpretation
#graphs
#mod_model$graphslopes
```
---
# In-Class Activity

> A simulated data set containing information on ten thousand customers. The aim here is to predict which customers will default on their credit card debt.

```{r}
library(ISLR)
data=ISLR::Credit
```
---
# In-Class Activity

- Have a look at variables (?ISLR::Credit)

- Pick two continuous variables to model

- Plot their interaction and test for significance using both the spotlight and floodlight analyses

---
class: middle

# Categorical x Categorical Interaction
---
# 2 x 2 Between Factorial Dataset

- LaPaglia, Miller, and Protexter (2022)

  - Looked at the impact of instructor fluency and gender on test performance (Quiz)
  
  - *N* = 72 (49 females, 23 males)
  
  - 2 (Fluency: fluent, disfluent) x 2 (Gender: male, female) design

```{r}
gen<- read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/13_Interactions/in_gen_2x2.csv")

gen <- gen %>%
  mutate(Gender=as.factor(Gender), Fluency=as.factor(Fluency))
```

---
# Categorical x Categorical Interaction

- Factorial design (ANOVA)

  - Commonly used to refer to experiments where more than one factor is manipulated

  - 2-way (most common), 3-way factorial designs, 4-way... 

---
# 2-way (Factorial) ANOVA

- In the example above we have two factors:

  - Factor A (e.g., Gender) with 2 levels (e.g., male vs. female)
  - Factor B (e.g., Fluency) with 2 levels (e.g., Disfluency vs. Fluency)

- Fully crossed design

  - Every level of factor A is tested with every level of factor B
  - Total # groups (cells) is a x b

- We will see how to formulate in terms of model comparisons:

  - Main effect of A
  - Main effect of B
  - Interaction effect A x B
---
# Main Effects and Interactions

.pull-left[

```{r,echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("8diff.png")
```
]

.pull-right[

```{r,echo=FALSE, fig.align='center', out.width="100%"}

knitr::include_graphics("mp4.png")
```
]

---
# Model Comparisons

- Same approach as before

$$F = \frac{SS_{R}-SS_{F}/{df_{R}-df_{F}} (p-1)}{SS_{F}/df_F(N-p)} = \frac{MS_{model}}{MS_{error}}$$

1. Write the equation for the full and restricted models

2. Derive the equations for model error restricted and full

3. Derive the expressions for degrees of freedom df restricted and df full

4. End up with an equation for the F ratio

---
# Full Model

$$Y_{ijk} = \mu + \alpha_j + \beta_k + (\alpha* \beta)_{ijk}$$

- $Y_{ijk}$: is an individual score in the jth level of factor A and the kth level of factor B (i
indexes subjects within each (j,k) cell)

-  $µ$: is the overall mean of all cells
- $α_j$: is the effect of the jth level of factor A
- $β_k$: is the effect of the kth level of factor B
- $(α · β)_{jk}$: is the interaction effect of level j of A and level k of B
---
# Modeling Approach to Hypothesis Testing 

- Two-Factor (A x B) design: 3 null hypotheses to be tested:

  - Main effect of A
  - Main effect of B
  - Interaction effect of A x B
  
- We will formulate a separate restricted model for each hypothesis test

$$F = \frac{SS_{R}-SS_{F}/{df_{R}-df_{F}} (p-1)}{SS_{F}/df_F(N-p)} = \frac{MS_{model}}{MS_{error}}$$

---
# Linear Modeling Approach: Treatment/Dummy Coding

```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Fluency, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```

$$\hat{Y}= b_0 + b_1{0} + b_2 {0} + b_3{0}$$
$$\bar Y_{Female,Disfluent} = b_0$$
---

```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```


$$\hat{Y}= b_0 + b_1{0} + b_2 {1} + b_3{0}$$

$$\bar Y_{Female,Fluent}= b_0 +  b_2$$
---
```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```

$$\hat{Y}= b_0 + b_1{1} + b_2 {0} + b_3{0}$$
$$\bar Y_{Male,Disfluent} = b_0 + b_1 {1}$$

---
```{r, echo=FALSE}

tibble::tribble(
     ~Gender, ~Language, ~D1, ~D2, ~Interaction,
  "Female=0",     "Disfluent=0",  0L,  0L,           0L,
  "Female=0",  "Fluent=1",  0L,  1L,           0L,
    "Male=1",     "Disfluent=0",  1L,  0L,           0L,
    "Male=1",  "Fluent=1",  1L,  1L,           1L
  )

```

$$\hat{Y}= b_0 + b_1{1} + b_2 {1} + b_3{1}$$

$$\bar Y_{Male,Fluent} = b_0+b_1{1} + b_2{1} + b_3{1} $$
---
# Fitting the model

- Fit this as a linear model

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  tidy()
```


---
# Marginal Means: Using `Emmeans`

```{r}

lm(Quiz~Gender*Fluency, data=gen) %>%
  emmeans::emmeans(specs=~Gender|Fluency) %>%
  as.data.frame()

```

---
# Marginal Means: Using `Easystats`

```{r}
library(modelbased) # load to use estimate_means
lm(Quiz~Gender*Fluency, data=gen) %>%
  estimate_means()
```

---
# Linear Modeling Approach: Sum-Coding

- Treatment coding tests simple effects in LM 
- Sum coding tests main effects/interaction effects (2 x 2)

```{r}
contrasts(gen$Gender) <- c(0.5, -0.5)# sum code gend
contrasts(gen$Fluency) <- c(0.5, -0.5)# sum code fluency
# fit linear model
lm(Quiz~Gender*Fluency, data=gen) %>%
  tidy()
```
---
# ANOVA 

- Sum coded LM is the same as running an ANOVA!

```{r}
library(afex)

aov_ez(id="id", between=c("Gender", "Fluency"), dv="Quiz", data=gen) %>%
  summary() %>% 
  tidy()
```
---
# Visualzing Categorical x Cateorgical Interactions

```{r, echo=FALSE, fig.align='center', out.width="100%"}
  aov_ez(id="id", between=c("Gender", "Fluency"), dv="Quiz", data=gen) %>%
  afex_plot(x="Fluency", trace="Gender", between=c("Fluency", "Gender"))
```
---
# Using the F Test: Sums of Squares  

```{r, echo=FALSE, fig.align='center', out.width="50%"}

knitr::include_graphics("ss_2x2.jpg")
```
---
# Main Effect of Gender $SS_A$

> Does Gender contribute significantly over and above an intercept-only model?

```{r,echo=FALSE}
knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ 1`",
  "Full/Alternative model:", "`Quiz ~ Gender`"
  ), col.names= c("", "")) %>%
  kableExtra::kable_material_dark()
```

---
# F-Statistic for Gender Main Effect: $SS_A$

```{r, echo=FALSE}
r = lm(Quiz~1, data=gen) # intercept-only
f = lm(Quiz~Gender, data=gen) # gender

anova(r, f) %>% 
tidy()#  allows us to compare models 
```

---
# Main Effect of *B*

> Does Fluency contribute meaningfully to the model over and above Gender?

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ Gender`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency`"
  ), col.names= c("", "")) %>%
  kableExtra::kable_material_dark()
```


---
# F-Statistic for Fluency Main Effect: $SS_B$

.pull-left[
```{r, echo=FALSE}

r = lm(Quiz~Gender, data=gen) # gender-only
f = lm(Quiz~Gender + Fluency , data=gen) # gender + Fluency

anova(r, f) %>%
   tidy()
  
```
]
---
# Interaction Effect of *AB*

> Does the interaction between Fluency and Gender contribute meaningfully to the model over and above the main effects?

```{r, echo=FALSE}

knitr::kable(tibble::tribble(
                   ~V1,                ~V2,
         "Restricted/Null model:",     "`Quiz ~ Gender + Fluency`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency + Gender:Fluency`"
  ), col.names= c("", "")) %>%
  kableExtra::kable_material_dark()

```
---
# F-Statistic for Gender*Fluency Effect: $SS_{AB}$

```{r, echo=FALSE}
r = lm(Quiz~Gender+Fluency, data=gen) # main effects only
f = lm(Quiz~Gender+Fluency + Fluency:Gender, data=gen) # main +inter

anova(r, f) %>%
  knitr::kable( digits=3) %>% # compare both models %>%
kableExtra::kable_material_dark()

```

---
# Full ANOVA Table
```{r, echo=FALSE, fig.align='center', out.width="100%"}
# aov uses type 1 ss
aov(lm(Quiz~Gender*Fluency, data=gen)) %>% tidy(digits=3)
```

---
# Type I, Type II, and Type III SS

- By default R `aov` calculates Type I (SS)

  - Sequential (order listed in model) 
  
    - First assign a maximum of variation to variable A
    
    - In the remaining variation, assign the maximum of variation to variable B

    - In the remaining variation, assign the maximum of variation to the interaction effect
    
    -  Assign the rest to the residual SS
    
- *Can change depending on order terms are placed in the model*
  
---
# Type I, Type II, and Type III ANOVAs

- Type II

  - Hierarchical SS 
  
    - Based the marginality principle which states that you should not omit a lower order term from your model if there are any higher order ones that depend on it
  
  - Tests main effects first
  - Ignores interactions
  
$$SS(A | B) A$$
$$SS(B | A) B$$

---
# Type II SS

- Main effect Gender

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Fluency`",
  "Full/Alternative model:", "`Quiz ~ Fluency  + Gender`"
  ), col.names = c("", "")) %>% 
  kableExtra::kable_material_dark()

```

- Main effect Fluency

```{r, echo=FALSE}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Gender`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency`"
  ), col.names = c("", "")) %>%
  kableExtra::kable_material_dark()

```
---
# Type II SS

- `Anova` function in `car` package can handle these cases

```{r}
library(car)

Anova(lm(Quiz~Gender*Fluency, data=gen), type="II") %>%
  tidy()
```
---
# Type I, Type II, and Type III SS

- Type III

  - Treats main effects and interactions simultaneously
  
  - Fit full model and remove effect of interest
  
    - How much of the variance is accounted for by X after taking into consideration all the other effects
    
- *Preferable if unequal cell sizes*
  
```{r, echo=FALSE}
knitr::kable(tibble::tribble(
                   ~V1,                                               ~V2,
         "Reduced/Null model:",     "`Quiz ~ Fluency + Gender:Fluency`",
  "Full/Alternative model:", "`Quiz ~ Gender + Fluency + Gender:Fluency`"
  ), col.names = c("", "")) %>%
  kableExtra::kable_material_dark()
```
---

```{r, echo=FALSE}
options(contrasts = c("contr.sum","contr.poly"))

Anova(lm(Quiz~Gender*Fluency, data=gen), type="III") %>%
  tidy()

model <- lm(Quiz~Gender*Fluency, data=gen)
drop1(model, .~., test="F") # DROP 1 effect and compare to full model
```
---
# Testing Categorical x Categorial Interactions

- First look at the interaction effect

  - IF interaction effect is significant, perform mean comparisons (e.g., *F* or *t*)

      - DON’T bother looking at involved main effects (not informative)
  
  - If not, follow-up with main effect comparisons

*For learning purposes we will examine the interaction*  

---
# Simple Effects Analysis

- An examination of one factor at the level of another

  Our example:
  
  - Difference in quiz performance for videos with Males and Females at Disfluent    
  - Difference in quiz performance for videos with Males and Females at Fluent

    - Get F test for these comparisons (2 one-way ANOVAs)
    
      $$F=\frac{MS_{gender_{oneway}}}{MS_{W_{omnibus}}}$$
---
# Simple Effects Analysis

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  emmeans::emmeans(pairwise~Gender|Fluency) %>%
  joint_tests(by="Fluency")
```
- Simple effect for Fluency, *F*(1, 46) = 0.29, *p* = .867

- Simple effect for Disfluency, *F*(1, 46) = 0.596, *p* = .867

---
# As *t*-tests

```{r}
lm(Quiz~Gender*Fluency, data=gen) %>%
  emmeans::emmeans(., ~Gender|Fluency) %>% 
  pairs(adjust="bon") # in 2x2 design does not need to be corrected as it is only one test per family
```
---
# Effect Sizes for Simple Effects
```{r}

# get eta 
t_to_eta2(
  t = c(0.169, 0.772),
  df_error = 46
)

# get omega 
#t_to_omega2(
 # t = c(0.169, 0.772),
  #df_error = 46
#)
```

---
# Effect Sizes: Main Effects and Interaction

-Report $eta_p^2$ or $\omega_2^2$ for Main Effects and interactions

```{r}

lm(Quiz~Gender*Fluency, data=gen) %>%
  effectsize::omega_squared()
 
```
---
# ANOVA Power

- `Superpower`

.pull-left[
```{r, fig.align='center', out.width="100%"}
string <- "2b*2b"
n <- 100
# We are thinking of running 100 people in each condition
mu <- c(7.25, 6.38, 7.38, 7)
# Enter means in the order that matches the labels below.
# In this case, control, pet.
sd <-c(1.76,1.80,2.63,1.54)
labelnames <- c("Gender", "male", "female", "Flu", "Disfluency", "Fluency") #
# the label names should be in the order of the means specified above.
```
]

.pull-right[
```{r,fig.align='center', out.width="100%"}
design_result <- ANOVA_design(design = string,
                   n = n,
                   mu = mu,
                   sd = sd,
                   labelnames = labelnames)

```
]

---
# Run Simulation

```{r}
#100 is not enough
simulation_result <- ANOVA_power(design_result, 
                                 alpha_level = .05, 
                                 nsims = 100,
                                 verbose = FALSE)

simulation_result
```

---
# 2 x 2 ANOVA Assumptions 

- Remember to check for normality and homogeneity before running 

```{r, eval=FALSE}

lm(Quiz~Gender*Fluency, data=gen) %>%
  check_normality() %>%
  check_homogeneity()

```
---
# Reporting Results

I would report the three effects from this model as follows:

  - Main effect 1
  - Main effect 2
  - Interaction

    - *M* and *SD* for main effects
    - Significance tests (F, degrees of freedom, p, effect size)
      - If interaction is significant, simple effects analysis
          - Interpretation of simple effects
          
    - Figure visualizing either the main effects (if interaction is not significant) or interaction

---
# Thoughts on Interactions

1. Avoid them if not theoretically motivated

  - Use contrasts when you can 
  - Use model comparison approach to determine if interactions are warranted
  
2. Testing interactions require lots of data
  
    - Power is worse in observational studies compared to experimental paradigms
    
3. Center continuous variables and sum code categorical predictors 

4. For non-simple designs (> 2:2) use `afex::aov_ez` (uses Type III SS)
---
# Class Activity

Does dress attire and tattoos influence how long a person will interact with a stranger asking for directions?

- Time (in s): Long long person interacted
- Tattoos: 0 (no tat visible) 1(tat visible)
- Dress: 0 (causal dress) 1 (professional dress)

```{r}
data=read_csv("https://raw.githubusercontent.com/jgeller112/psy503-psych_stats/master/static/slides/13_Interactions/data/tats.csv")
```
- Conduct 2 x 2 ANOVA (discuss main effects and interaction effects)
- Follow-up interaction with simple effects analysis
- Create a figure of results


